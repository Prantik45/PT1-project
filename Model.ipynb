{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d49b5346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "from sklearn.metrics import log_loss,roc_auc_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "import pickle\n",
    "from prettytable import PrettyTable\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b8854f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>destination</th>\n",
       "      <th>passanger</th>\n",
       "      <th>weather</th>\n",
       "      <th>temperature</th>\n",
       "      <th>time</th>\n",
       "      <th>coupon</th>\n",
       "      <th>expiration</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>maritalStatus</th>\n",
       "      <th>...</th>\n",
       "      <th>CoffeeHouse</th>\n",
       "      <th>CarryAway</th>\n",
       "      <th>RestaurantLessThan20</th>\n",
       "      <th>Restaurant20To50</th>\n",
       "      <th>toCoupon_GEQ5min</th>\n",
       "      <th>toCoupon_GEQ15min</th>\n",
       "      <th>toCoupon_GEQ25min</th>\n",
       "      <th>direction_same</th>\n",
       "      <th>direction_opp</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No Urgent Place</td>\n",
       "      <td>Alone</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>55</td>\n",
       "      <td>2PM</td>\n",
       "      <td>Restaurant(&lt;20)</td>\n",
       "      <td>1d</td>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>Unmarried partner</td>\n",
       "      <td>...</td>\n",
       "      <td>never</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4~8</td>\n",
       "      <td>1~3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Urgent Place</td>\n",
       "      <td>Friend(s)</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>80</td>\n",
       "      <td>10AM</td>\n",
       "      <td>Coffee House</td>\n",
       "      <td>2h</td>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>Unmarried partner</td>\n",
       "      <td>...</td>\n",
       "      <td>never</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4~8</td>\n",
       "      <td>1~3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No Urgent Place</td>\n",
       "      <td>Friend(s)</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>80</td>\n",
       "      <td>10AM</td>\n",
       "      <td>Carry out &amp; Take away</td>\n",
       "      <td>2h</td>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>Unmarried partner</td>\n",
       "      <td>...</td>\n",
       "      <td>never</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4~8</td>\n",
       "      <td>1~3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No Urgent Place</td>\n",
       "      <td>Friend(s)</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>80</td>\n",
       "      <td>2PM</td>\n",
       "      <td>Coffee House</td>\n",
       "      <td>2h</td>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>Unmarried partner</td>\n",
       "      <td>...</td>\n",
       "      <td>never</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4~8</td>\n",
       "      <td>1~3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No Urgent Place</td>\n",
       "      <td>Friend(s)</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>80</td>\n",
       "      <td>2PM</td>\n",
       "      <td>Coffee House</td>\n",
       "      <td>1d</td>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>Unmarried partner</td>\n",
       "      <td>...</td>\n",
       "      <td>never</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4~8</td>\n",
       "      <td>1~3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       destination  passanger weather  temperature  time  \\\n",
       "0  No Urgent Place      Alone   Sunny           55   2PM   \n",
       "1  No Urgent Place  Friend(s)   Sunny           80  10AM   \n",
       "2  No Urgent Place  Friend(s)   Sunny           80  10AM   \n",
       "3  No Urgent Place  Friend(s)   Sunny           80   2PM   \n",
       "4  No Urgent Place  Friend(s)   Sunny           80   2PM   \n",
       "\n",
       "                  coupon expiration  gender age      maritalStatus  ...  \\\n",
       "0        Restaurant(<20)         1d  Female  21  Unmarried partner  ...   \n",
       "1           Coffee House         2h  Female  21  Unmarried partner  ...   \n",
       "2  Carry out & Take away         2h  Female  21  Unmarried partner  ...   \n",
       "3           Coffee House         2h  Female  21  Unmarried partner  ...   \n",
       "4           Coffee House         1d  Female  21  Unmarried partner  ...   \n",
       "\n",
       "   CoffeeHouse CarryAway RestaurantLessThan20 Restaurant20To50  \\\n",
       "0        never       NaN                  4~8              1~3   \n",
       "1        never       NaN                  4~8              1~3   \n",
       "2        never       NaN                  4~8              1~3   \n",
       "3        never       NaN                  4~8              1~3   \n",
       "4        never       NaN                  4~8              1~3   \n",
       "\n",
       "  toCoupon_GEQ5min toCoupon_GEQ15min toCoupon_GEQ25min direction_same  \\\n",
       "0                1                 0                 0              0   \n",
       "1                1                 0                 0              0   \n",
       "2                1                 1                 0              0   \n",
       "3                1                 1                 0              0   \n",
       "4                1                 1                 0              0   \n",
       "\n",
       "  direction_opp  Y  \n",
       "0             1  1  \n",
       "1             1  0  \n",
       "2             1  1  \n",
       "3             1  0  \n",
       "4             1  0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('in-vehicle-coupon-recommendation.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0c423ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points: 12684\n",
      "Number of features: 26\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The attributes of data : ['destination' 'passanger' 'weather' 'temperature' 'time' 'coupon'\n",
      " 'expiration' 'gender' 'age' 'maritalStatus' 'has_children' 'education'\n",
      " 'occupation' 'income' 'car' 'Bar' 'CoffeeHouse' 'CarryAway'\n",
      " 'RestaurantLessThan20' 'Restaurant20To50' 'toCoupon_GEQ5min'\n",
      " 'toCoupon_GEQ15min' 'toCoupon_GEQ25min' 'direction_same' 'direction_opp'\n",
      " 'Y']\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of data points:\", data.shape[0])\n",
    "print(\"Number of features:\", data.shape[1])\n",
    "print('-'*100)\n",
    "print(\"The attributes of data :\", data.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bab5cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of users that are accepted the coupon is  7210 , 56.843 %\n",
      "The number of users that are rejected the coupon is  5474 , 43.157 %\n"
     ]
    }
   ],
   "source": [
    "Y_value_counts = data.groupby('Y').Y.count()\n",
    "print('The number of users that are accepted the coupon is ',Y_value_counts[1],',',round(Y_value_counts[1]/data.shape[0]*100,3),'%')\n",
    "print('The number of users that are rejected the coupon is ',Y_value_counts[0],',',round(Y_value_counts[0]/data.shape[0]*100,3),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0542006e",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbba8ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['Y'], axis=1)\n",
    "y = data['Y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5e9c1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6feffb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10147, 25) (10147,)\n",
      "(2537, 25) (2537,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd50d1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10147 entries, 1753 to 6971\n",
      "Data columns (total 25 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   destination           10147 non-null  object\n",
      " 1   passanger             10147 non-null  object\n",
      " 2   weather               10147 non-null  object\n",
      " 3   temperature           10147 non-null  int64 \n",
      " 4   time                  10147 non-null  object\n",
      " 5   coupon                10147 non-null  object\n",
      " 6   expiration            10147 non-null  object\n",
      " 7   gender                10147 non-null  object\n",
      " 8   age                   10147 non-null  object\n",
      " 9   maritalStatus         10147 non-null  object\n",
      " 10  has_children          10147 non-null  int64 \n",
      " 11  education             10147 non-null  object\n",
      " 12  occupation            10147 non-null  object\n",
      " 13  income                10147 non-null  object\n",
      " 14  car                   90 non-null     object\n",
      " 15  Bar                   10060 non-null  object\n",
      " 16  CoffeeHouse           9975 non-null   object\n",
      " 17  CarryAway             10024 non-null  object\n",
      " 18  RestaurantLessThan20  10040 non-null  object\n",
      " 19  Restaurant20To50      9990 non-null   object\n",
      " 20  toCoupon_GEQ5min      10147 non-null  int64 \n",
      " 21  toCoupon_GEQ15min     10147 non-null  int64 \n",
      " 22  toCoupon_GEQ25min     10147 non-null  int64 \n",
      " 23  direction_same        10147 non-null  int64 \n",
      " 24  direction_opp         10147 non-null  int64 \n",
      "dtypes: int64(7), object(18)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18144b7f",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c31f5014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "# duplicate = data[data.duplicated(keep = 'last')]\n",
    "# # duplicate.shape #(74, 26)\n",
    "# data = data.drop_duplicates()\n",
    "# print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43928a67",
   "metadata": {},
   "source": [
    "#### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b255e785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there any missing value present or not? True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing_count</th>\n",
       "      <th>missing_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>car</th>\n",
       "      <td>12576</td>\n",
       "      <td>99.148534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bar</th>\n",
       "      <td>107</td>\n",
       "      <td>0.843582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoffeeHouse</th>\n",
       "      <td>217</td>\n",
       "      <td>1.710817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CarryAway</th>\n",
       "      <td>151</td>\n",
       "      <td>1.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RestaurantLessThan20</th>\n",
       "      <td>130</td>\n",
       "      <td>1.024913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Restaurant20To50</th>\n",
       "      <td>189</td>\n",
       "      <td>1.490066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      missing_count  missing_percentage\n",
       "car                           12576           99.148534\n",
       "Bar                             107            0.843582\n",
       "CoffeeHouse                     217            1.710817\n",
       "CarryAway                       151            1.190476\n",
       "RestaurantLessThan20            130            1.024913\n",
       "Restaurant20To50                189            1.490066"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Is there any missing value present or not?',data.isnull().values.any())\n",
    "missing_percentage = data.isnull().sum()*100/len(data)\n",
    "missing_value_df = pd.DataFrame({'missing_count': data.isnull().sum(),'missing_percentage': missing_percentage})\n",
    "missing_value_df[missing_value_df.missing_count != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c716055",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['car'], axis=1)\n",
    "X_test = X_test.drop(['car'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5eab4ff",
   "metadata": {},
   "source": [
    "#### Correlation of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2cd06f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>has_children</th>\n",
       "      <th>toCoupon_GEQ5min</th>\n",
       "      <th>toCoupon_GEQ15min</th>\n",
       "      <th>toCoupon_GEQ25min</th>\n",
       "      <th>direction_same</th>\n",
       "      <th>direction_opp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>temperature</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.023556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.146644</td>\n",
       "      <td>-0.205937</td>\n",
       "      <td>0.092944</td>\n",
       "      <td>-0.092944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_children</th>\n",
       "      <td>-0.023556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.081037</td>\n",
       "      <td>-0.013570</td>\n",
       "      <td>-0.036979</td>\n",
       "      <td>0.036979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toCoupon_GEQ5min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toCoupon_GEQ15min</th>\n",
       "      <td>-0.146644</td>\n",
       "      <td>0.081037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.322756</td>\n",
       "      <td>-0.300537</td>\n",
       "      <td>0.300537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toCoupon_GEQ25min</th>\n",
       "      <td>-0.205937</td>\n",
       "      <td>-0.013570</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.322756</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.190973</td>\n",
       "      <td>0.190973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>direction_same</th>\n",
       "      <td>0.092944</td>\n",
       "      <td>-0.036979</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.300537</td>\n",
       "      <td>-0.190973</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>direction_opp</th>\n",
       "      <td>-0.092944</td>\n",
       "      <td>0.036979</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.300537</td>\n",
       "      <td>0.190973</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   temperature  has_children  toCoupon_GEQ5min  \\\n",
       "temperature           1.000000     -0.023556               NaN   \n",
       "has_children         -0.023556      1.000000               NaN   \n",
       "toCoupon_GEQ5min           NaN           NaN               NaN   \n",
       "toCoupon_GEQ15min    -0.146644      0.081037               NaN   \n",
       "toCoupon_GEQ25min    -0.205937     -0.013570               NaN   \n",
       "direction_same        0.092944     -0.036979               NaN   \n",
       "direction_opp        -0.092944      0.036979               NaN   \n",
       "\n",
       "                   toCoupon_GEQ15min  toCoupon_GEQ25min  direction_same  \\\n",
       "temperature                -0.146644          -0.205937        0.092944   \n",
       "has_children                0.081037          -0.013570       -0.036979   \n",
       "toCoupon_GEQ5min                 NaN                NaN             NaN   \n",
       "toCoupon_GEQ15min           1.000000           0.322756       -0.300537   \n",
       "toCoupon_GEQ25min           0.322756           1.000000       -0.190973   \n",
       "direction_same             -0.300537          -0.190973        1.000000   \n",
       "direction_opp               0.300537           0.190973       -1.000000   \n",
       "\n",
       "                   direction_opp  \n",
       "temperature            -0.092944  \n",
       "has_children            0.036979  \n",
       "toCoupon_GEQ5min             NaN  \n",
       "toCoupon_GEQ15min       0.300537  \n",
       "toCoupon_GEQ25min       0.190973  \n",
       "direction_same         -1.000000  \n",
       "direction_opp           1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd991d2a",
   "metadata": {},
   "source": [
    "  1.Feature â€˜direction_sameâ€™ is perfectly correlated with â€˜direction_oppâ€™, both     have the same variance.\n",
    "  \n",
    "  2.â€˜toCoupon_GEQ5minâ€™ feature has no correlation with any feature because it        has the same value â€˜1â€™ for all data points, which means all the                restaurants/bars are at least more than five minutes away from the driver.\n",
    "  \n",
    "  so, drop both 'direction_opp' and 'toCoupon_GEQ5min' features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae6d9d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10147, 22), (2537, 22))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.drop(['direction_opp','toCoupon_GEQ5min'], axis=1)\n",
    "X_test = X_test.drop(['direction_opp','toCoupon_GEQ5min'], axis=1)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47f4efc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>has_children</th>\n",
       "      <th>toCoupon_GEQ15min</th>\n",
       "      <th>toCoupon_GEQ25min</th>\n",
       "      <th>direction_same</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10147.000000</td>\n",
       "      <td>10147.000000</td>\n",
       "      <td>10147.000000</td>\n",
       "      <td>10147.000000</td>\n",
       "      <td>10147.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>63.354686</td>\n",
       "      <td>0.415295</td>\n",
       "      <td>0.561447</td>\n",
       "      <td>0.117670</td>\n",
       "      <td>0.214743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>19.160522</td>\n",
       "      <td>0.492797</td>\n",
       "      <td>0.496234</td>\n",
       "      <td>0.322233</td>\n",
       "      <td>0.410664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        temperature  has_children  toCoupon_GEQ15min  toCoupon_GEQ25min  \\\n",
       "count  10147.000000  10147.000000       10147.000000       10147.000000   \n",
       "mean      63.354686      0.415295           0.561447           0.117670   \n",
       "std       19.160522      0.492797           0.496234           0.322233   \n",
       "min       30.000000      0.000000           0.000000           0.000000   \n",
       "25%       55.000000      0.000000           0.000000           0.000000   \n",
       "50%       80.000000      0.000000           1.000000           0.000000   \n",
       "75%       80.000000      1.000000           1.000000           0.000000   \n",
       "max       80.000000      1.000000           1.000000           1.000000   \n",
       "\n",
       "       direction_same  \n",
       "count    10147.000000  \n",
       "mean         0.214743  \n",
       "std          0.410664  \n",
       "min          0.000000  \n",
       "25%          0.000000  \n",
       "50%          0.000000  \n",
       "75%          0.000000  \n",
       "max          1.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d33b27",
   "metadata": {},
   "source": [
    "## Mode Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fd38f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there any missing value present or not? True\n"
     ]
    }
   ],
   "source": [
    "print('Is there any missing value present or not?',X_train.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13aa7035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode imputation for missing values in train data\n",
    "X_train['Bar'] = X_train['Bar'].fillna(X_train['Bar'].value_counts().index[0])\n",
    "X_train['CoffeeHouse'] = X_train['CoffeeHouse'].fillna(X_train['CoffeeHouse'].value_counts().index[0])\n",
    "X_train['CarryAway'] = X_train['CarryAway'].fillna(X_train['CarryAway'].value_counts().index[0])\n",
    "X_train['RestaurantLessThan20'] = X_train['RestaurantLessThan20'].fillna(X_train['RestaurantLessThan20'].value_counts().index[0])\n",
    "X_train['Restaurant20To50'] = X_train['Restaurant20To50'].fillna(X_train['Restaurant20To50'].value_counts().index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ae25ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode imputation for missing values in test data\n",
    "X_test['Bar'] = X_test['Bar'].fillna(X_train['Bar'].value_counts().index[0])\n",
    "X_test['CoffeeHouse'] = X_test['CoffeeHouse'].fillna(X_train['CoffeeHouse'].value_counts().index[0])\n",
    "X_test['CarryAway'] = X_test['CarryAway'].fillna(X_train['CarryAway'].value_counts().index[0])\n",
    "X_test['RestaurantLessThan20'] = X_test['RestaurantLessThan20'].fillna(X_train['RestaurantLessThan20'].value_counts().index[0])\n",
    "X_test['Restaurant20To50'] = X_test['Restaurant20To50'].fillna(X_train['Restaurant20To50'].value_counts().index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47678dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there any missing value present in X_train? False\n"
     ]
    }
   ],
   "source": [
    "print('Is there any missing value present in X_train?',X_train.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "595347b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there any missing value present in X_test? False\n"
     ]
    }
   ],
   "source": [
    "print('Is there any missing value present in X_test?',X_test.isnull().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490f9042",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9045e6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values: [0 1 2]\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    10147.000000\n",
       "mean         0.679117\n",
       "std          0.673277\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          1.000000\n",
       "75%          1.000000\n",
       "max          2.000000\n",
       "Name: to_Coupon, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FE -- to_Coupon is combination of two features, toCoupon_GEQ15min and toCoupon_GEQ25min\n",
    "to_Coupon = []\n",
    "for i in range(X_train.shape[0]):\n",
    "    if (list(X_train['toCoupon_GEQ15min'])[i] == 0):\n",
    "        to_Coupon.append(0)\n",
    "    elif (list(X_train['toCoupon_GEQ15min'])[i] == 1)and(list(X_train['toCoupon_GEQ25min'])[i] == 0):\n",
    "        to_Coupon.append(1)\n",
    "    else:\n",
    "        to_Coupon.append(2)\n",
    "        \n",
    "X_train['to_Coupon'] = to_Coupon\n",
    "print('Unique values:',X_train['to_Coupon'].unique())\n",
    "print('-'*50)\n",
    "X_train['to_Coupon'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e525a704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values: [0 1 2]\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    2537.000000\n",
       "mean        0.686638\n",
       "std         0.682093\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         1.000000\n",
       "75%         1.000000\n",
       "max         2.000000\n",
       "Name: to_Coupon, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FE -- to_Coupon is combination of two features, toCoupon_GEQ15min and toCoupon_GEQ25min\n",
    "to_Coupon = []\n",
    "for i in range(X_test.shape[0]):\n",
    "    if (list(X_test['toCoupon_GEQ15min'])[i] == 0):\n",
    "        to_Coupon.append(0)\n",
    "    elif (list(X_test['toCoupon_GEQ15min'])[i] == 1)and(list(X_test['toCoupon_GEQ25min'])[i] == 0):\n",
    "        to_Coupon.append(1)\n",
    "    else:\n",
    "        to_Coupon.append(2)\n",
    "        \n",
    "X_test['to_Coupon'] = to_Coupon\n",
    "print('Unique values:',X_test['to_Coupon'].unique())\n",
    "print('-'*50)\n",
    "X_test['to_Coupon'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6474d4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values: ['1~3' '4~8' 'gt8' 'less1' 'never']\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count     10147\n",
       "unique        5\n",
       "top         1~3\n",
       "freq       3118\n",
       "Name: coupon_freq, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FE -- coupon_freq is combination of five features, RestaurantLessThan20, CoffeeHouse, CarryAway, Bar, Restaurant20To50\n",
    "coupon_freq = []\n",
    "for i in range(X_train.shape[0]):\n",
    "    if (list(X_train['coupon'])[i] == 'Restaurant(<20)'):\n",
    "        coupon_freq.append(list(X_train['RestaurantLessThan20'])[i])\n",
    "    elif (list(X_train['coupon'])[i] == 'Coffee House'):\n",
    "        coupon_freq.append(list(X_train['CoffeeHouse'])[i])\n",
    "    elif (list(X_train['coupon'])[i] == 'Carry out & Take away'):\n",
    "        coupon_freq.append(list(X_train['CarryAway'])[i])\n",
    "    elif (list(X_train['coupon'])[i] == 'Bar'):\n",
    "        coupon_freq.append(list(X_train['Bar'])[i])\n",
    "    elif (list(X_train['coupon'])[i] == 'Restaurant(20-50)'):\n",
    "        coupon_freq.append(list(X_train['Restaurant20To50'])[i])\n",
    "        \n",
    "X_train['coupon_freq'] = coupon_freq\n",
    "print('Unique values:',X_train['coupon_freq'].unique())\n",
    "print('-'*50)\n",
    "X_train['coupon_freq'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25200f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values: ['4~8' 'less1' 'never' '1~3' 'gt8']\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count     2537\n",
       "unique       5\n",
       "top        1~3\n",
       "freq       774\n",
       "Name: coupon_freq, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FE -- coupon_freq is combination of five features, RestaurantLessThan20, CoffeeHouse, CarryAway, Bar, Restaurant20To50\n",
    "coupon_freq = []\n",
    "for i in range(X_test.shape[0]):\n",
    "    if (list(X_test['coupon'])[i] == 'Restaurant(<20)'):\n",
    "        coupon_freq.append(list(X_test['RestaurantLessThan20'])[i])\n",
    "    elif (list(X_test['coupon'])[i] == 'Coffee House'):\n",
    "        coupon_freq.append(list(X_test['CoffeeHouse'])[i])\n",
    "    elif (list(X_test['coupon'])[i] == 'Carry out & Take away'):\n",
    "        coupon_freq.append(list(X_test['CarryAway'])[i])\n",
    "    elif (list(X_test['coupon'])[i] == 'Bar'):\n",
    "        coupon_freq.append(list(X_test['Bar'])[i])\n",
    "    elif (list(X_test['coupon'])[i] == 'Restaurant(20-50)'):\n",
    "        coupon_freq.append(list(X_test['Restaurant20To50'])[i])\n",
    "        \n",
    "X_test['coupon_freq'] = coupon_freq\n",
    "print('Unique values:',X_test['coupon_freq'].unique()) \n",
    "print('-'*50)\n",
    "X_test['coupon_freq'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f32aa178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count          10147\n",
       "unique            25\n",
       "top       Unemployed\n",
       "freq            1525\n",
       "Name: occupation, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['occupation'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e992b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values: ['Low_Acceptance' 'Medium_High_Acceptance' 'Medium_Low_Acceptance'\n",
      " 'Medium_Acceptance' 'High_Acceptance']\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count                     10147\n",
       "unique                        5\n",
       "top       Medium_Low_Acceptance\n",
       "freq                       2672\n",
       "Name: occupation_class, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# occupation feature has 25 no of distinct values, which creates very sparsity in data after Encoding\n",
    "# FE -- occupation_class where categorize all occupation in its suitable class.\n",
    "occupation_dict = {'Healthcare Support':'High_Acceptance','Construction & Extraction':'High_Acceptance','Healthcare Practitioners & Technical':'High_Acceptance',\n",
    "                   'Protective Service':'High_Acceptance','Architecture & Engineering':'High_Acceptance','Production Occupations':'Medium_High_Acceptance',\n",
    "                    'Student':'Medium_High_Acceptance','Office & Administrative Support':'Medium_High_Acceptance','Transportation & Material Moving':'Medium_High_Acceptance',\n",
    "                    'Building & Grounds Cleaning & Maintenance':'Medium_High_Acceptance','Management':'Medium_Acceptance','Food Preparation & Serving Related':'Medium_Acceptance',\n",
    "                   'Life Physical Social Science':'Medium_Acceptance','Business & Financial':'Medium_Acceptance','Computer & Mathematical':'Medium_Acceptance',\n",
    "                    'Sales & Related':'Medium_Low_Acceptance','Personal Care & Service':'Medium_Low_Acceptance','Unemployed':'Medium_Low_Acceptance',\n",
    "                   'Farming Fishing & Forestry':'Medium_Low_Acceptance','Installation Maintenance & Repair':'Medium_Low_Acceptance','Education&Training&Library':'Low_Acceptance',\n",
    "                    'Arts Design Entertainment Sports & Media':'Low_Acceptance','Community & Social Services':'Low_Acceptance','Legal':'Low_Acceptance','Retired':'Low_Acceptance'}\n",
    "# occupation_dict\n",
    "X_train['occupation_class'] = X_train['occupation'].map(occupation_dict)\n",
    "print('Unique values:',X_train['occupation_class'].unique())\n",
    "print('-'*50)\n",
    "X_train['occupation_class'].describe()\n",
    "# X_train['occupation_class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a95bdbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count           2537\n",
       "unique            25\n",
       "top       Unemployed\n",
       "freq             345\n",
       "Name: occupation, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['occupation'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "561c3123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values: ['Medium_Acceptance' 'High_Acceptance' 'Low_Acceptance'\n",
      " 'Medium_High_Acceptance' 'Medium_Low_Acceptance']\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count                  2537\n",
       "unique                    5\n",
       "top       Medium_Acceptance\n",
       "freq                    679\n",
       "Name: occupation_class, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# occupation feature has 25 no of distinct values, which creates very sparsity in data after Encoding\n",
    "# FE -- occupation_class where categorize all occupation in its suitable class.\n",
    "occupation_dict = {'Healthcare Support':'High_Acceptance','Construction & Extraction':'High_Acceptance','Healthcare Practitioners & Technical':'High_Acceptance',\n",
    "                   'Protective Service':'High_Acceptance','Architecture & Engineering':'High_Acceptance','Production Occupations':'Medium_High_Acceptance',\n",
    "                    'Student':'Medium_High_Acceptance','Office & Administrative Support':'Medium_High_Acceptance','Transportation & Material Moving':'Medium_High_Acceptance',\n",
    "                    'Building & Grounds Cleaning & Maintenance':'Medium_High_Acceptance','Management':'Medium_Acceptance','Food Preparation & Serving Related':'Medium_Acceptance',\n",
    "                   'Life Physical Social Science':'Medium_Acceptance','Business & Financial':'Medium_Acceptance','Computer & Mathematical':'Medium_Acceptance',\n",
    "                    'Sales & Related':'Medium_Low_Acceptance','Personal Care & Service':'Medium_Low_Acceptance','Unemployed':'Medium_Low_Acceptance',\n",
    "                   'Farming Fishing & Forestry':'Medium_Low_Acceptance','Installation Maintenance & Repair':'Medium_Low_Acceptance','Education&Training&Library':'Low_Acceptance',\n",
    "                    'Arts Design Entertainment Sports & Media':'Low_Acceptance','Community & Social Services':'Low_Acceptance','Legal':'Low_Acceptance','Retired':'Low_Acceptance'}\n",
    "# occupation_dict\n",
    "X_test['occupation_class'] = X_test['occupation'].map(occupation_dict)\n",
    "print('Unique values:',X_test['occupation_class'].unique())\n",
    "print('-'*50)\n",
    "X_test['occupation_class'].describe()\n",
    "# X_test['occupation_class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd73ac27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (10147, 24) \n",
      "X_test: (2537, 24)\n",
      "--------------------------------------------------\n",
      "['destination' 'passanger' 'weather' 'temperature' 'time' 'coupon'\n",
      " 'expiration' 'gender' 'age' 'maritalStatus' 'has_children' 'education'\n",
      " 'income' 'Bar' 'CoffeeHouse' 'CarryAway' 'RestaurantLessThan20'\n",
      " 'Restaurant20To50' 'toCoupon_GEQ15min' 'toCoupon_GEQ25min'\n",
      " 'direction_same' 'to_Coupon' 'coupon_freq' 'occupation_class']\n"
     ]
    }
   ],
   "source": [
    "# After Feature Engineering, removing unwanted features\n",
    "# X_train = X_train.drop(['toCoupon_GEQ15min','toCoupon_GEQ25min','Bar','CoffeeHouse','CarryAway','RestaurantLessThan20','Restaurant20To50','occupation'], axis=1)\n",
    "# X_test = X_test.drop(['toCoupon_GEQ15min','toCoupon_GEQ25min','Bar','CoffeeHouse','CarryAway','RestaurantLessThan20','Restaurant20To50','occupation'], axis=1)\n",
    "X_train = X_train.drop(['occupation'], axis=1)\n",
    "X_test = X_test.drop(['occupation'], axis=1)\n",
    "print('X_train:',X_train.shape,'\\nX_test:',X_test.shape)\n",
    "print('-'*50)\n",
    "print(X_train.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e107744e",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d549a54",
   "metadata": {},
   "source": [
    "### Ordinal Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "611d8a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "order = [['Work','Home','No Urgent Place'],['Kid(s)','Alone','Partner','Friend(s)'],['Rainy','Snowy','Sunny'],[30,55,80],['7AM','10AM','2PM','6PM','10PM'],\n",
    "         ['Bar','Restaurant(20-50)','Coffee House','Restaurant(<20)','Carry out & Take away'],['2h','1d'],['Female','Male'],['below21','21','26','31','36','41','46','50plus'],\n",
    "         ['Widowed','Divorced','Married partner','Unmarried partner','Single'],[0,1],\n",
    "         ['Some High School','High School Graduate','Some college - no degree','Associates degree','Bachelors degree','Graduate degree (Masters or Doctorate)'],\n",
    "         ['Less than $12500','$12500 - $24999','$25000 - $37499','$37500 - $49999','$50000 - $62499','$62500 - $74999','$75000 - $87499','$87500 - $99999','$100000 or More'],\n",
    "         ['never','less1','1~3','4~8','gt8'],['never','less1','1~3','4~8','gt8'],['never','less1','1~3','4~8','gt8'],['never','less1','1~3','4~8','gt8'],['never','less1','1~3','4~8','gt8'],\n",
    "         [0,1],[0,1],[0,1],[0,1,2],['never','less1','1~3','4~8','gt8'],['Low_Acceptance','Medium_Low_Acceptance','Medium_Acceptance','Medium_High_Acceptance','High_Acceptance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1804765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_Ordinal_encoding: (10147, 24)\n"
     ]
    }
   ],
   "source": [
    "Ordinal_enc = OrdinalEncoder(categories=order)\n",
    "X_train_Ordinal_encoding = Ordinal_enc.fit_transform(X_train)\n",
    "X_train_Ordinal_encoding = pd.DataFrame(X_train_Ordinal_encoding,columns=X_train.columns.values)\n",
    "print('X_train_Ordinal_encoding:',X_train_Ordinal_encoding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3e9a876c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_Ordinal_encoding: (2537, 24)\n"
     ]
    }
   ],
   "source": [
    "Ordinal_enc = OrdinalEncoder(categories=order)\n",
    "X_test_Ordinal_encoding = Ordinal_enc.fit_transform(X_test)\n",
    "X_test_Ordinal_encoding = pd.DataFrame(X_test_Ordinal_encoding,columns=X_test.columns.values)\n",
    "print('X_test_Ordinal_encoding:',X_test_Ordinal_encoding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc02fd8",
   "metadata": {},
   "source": [
    "### Frequency Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "19cd3652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_enc(column_name,X):\n",
    "  \"\"\"It returns Frequency encoded feature\"\"\"\n",
    "  return X[column_name].map(X.groupby(column_name).size()/len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4a6e3bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_frequency_encoding: (10147, 24)\n"
     ]
    }
   ],
   "source": [
    "X_train_frequency_encoding = pd.DataFrame()\n",
    "for i in range(X_train.shape[1]):\n",
    "  X_train_frequency_encoding[X_train.columns.values[i]+'_freq_enc'] = frequency_enc(X_train.columns.values[i],X_train)\n",
    "\n",
    "print('X_train_frequency_encoding:',X_train_frequency_encoding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "080fbf37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_frequency_encoding: (2537, 24)\n"
     ]
    }
   ],
   "source": [
    "X_test_frequency_encoding = pd.DataFrame()\n",
    "for i in range(X_test.shape[1]):\n",
    "  X_test_frequency_encoding[X_test.columns.values[i]+'_freq_enc'] = frequency_enc(X_test.columns.values[i],X_test)\n",
    "\n",
    "print('X_test_frequency_encoding:',X_test_frequency_encoding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf9f337",
   "metadata": {},
   "source": [
    "### Target Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5d684a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_target_encoding: (10147, 24)\n"
     ]
    }
   ],
   "source": [
    "def target_enc(column_name,X):\n",
    "  \"\"\"It returns Target encoded feature for train data\"\"\"\n",
    "  X['Y_train'] = y_train\n",
    "  return X[column_name].map(X.groupby(column_name)['Y_train'].mean())\n",
    "\n",
    "X_train_target_encoding = pd.DataFrame()\n",
    "for i in range(X_train.shape[1]):\n",
    "  X_train_target_encoding[X_train.columns.values[i]+'_target_enc'] = target_enc(X_train.columns.values[i],X_train)\n",
    "\n",
    "print('X_train_target_encoding:',X_train_target_encoding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9c72b92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_target_encoding: (2537, 24)\n"
     ]
    }
   ],
   "source": [
    "def target_enc(column_name,X):\n",
    "  \"\"\"It returns Target encoded feature for test data\"\"\"\n",
    "  X['Y_test'] = y_test\n",
    "  return X[column_name].map(X.groupby(column_name)['Y_test'].mean())\n",
    "\n",
    "X_test_target_encoding = pd.DataFrame()\n",
    "for i in range(X_test.shape[1]):\n",
    "  X_test_target_encoding[X_test.columns.values[i]+'_target_enc'] = target_enc(X_test.columns.values[i],X_test)\n",
    "\n",
    "print('X_test_target_encoding:',X_test_target_encoding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936c3c44",
   "metadata": {},
   "source": [
    "### Response Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "43d28b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response encoding function\n",
    "def response_coding(feature,X,Y):\n",
    "    \"\"\"It returns Response encoded feature\"\"\"\n",
    "    X[feature] = X[feature].str.replace('~','_')\n",
    "    X[feature] = X[feature].str.replace('[^a-zA-Z0-9_ ]',' ')\n",
    "    X[feature] = X[feature].str.replace(' +',' ')\n",
    "    X[feature] = X[feature].str.strip()\n",
    "    X[feature] = X[feature].str.replace(' ','_')\n",
    "    X[feature] = X[feature].str.lower()\n",
    "    response_code_0 = [];response_code_1 = []\n",
    "    unique_cat_features = X[feature].unique()\n",
    "    unique_cat_features = np.sort(unique_cat_features)\n",
    "    for i in range(len(unique_cat_features)):\n",
    "        total_count = X[feature][(X[feature] == unique_cat_features[i])].count()\n",
    "        p0 = (X[feature][((X[feature] == unique_cat_features[i]) & (Y==0))].count())/total_count\n",
    "        p1 = (X[feature][((X[feature] == unique_cat_features[i]) & (Y==1))].count())/total_count\n",
    "        response_code_0.append(p0);response_code_1.append(p1)\n",
    "    dict_response_code_0 = dict(zip(unique_cat_features, response_code_0))\n",
    "    dict_response_code_1 = dict(zip(unique_cat_features, response_code_1))\n",
    "    X_response_0 = X[feature].map(dict_response_code_0)\n",
    "    X_response_1 = X[feature].map(dict_response_code_1)\n",
    "    X_response_0 = X_response_0.values.reshape(-1,1)\n",
    "    X_response_1 = X_response_1.values.reshape(-1,1)\n",
    "    return X_response_0,X_response_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3faa0a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_destination_0,X_train_destination_1 = response_coding('destination',X_train,y_train)\n",
    "X_train_passanger_0,X_train_passanger_1 = response_coding('passanger',X_train,y_train)\n",
    "X_train_weather_0,X_train_weather_1 = response_coding('weather',X_train,y_train)\n",
    "X_train_time_0,X_train_time_1 = response_coding('time',X_train,y_train)\n",
    "X_train_coupon_0,X_train_coupon_1 = response_coding('coupon',X_train,y_train)\n",
    "X_train_expiration_0,X_train_expiration_1 = response_coding('expiration',X_train,y_train)\n",
    "X_train_gender_0,X_train_gender_1 = response_coding('gender',X_train,y_train)\n",
    "X_train_age_0,X_train_age_1 = response_coding('age',X_train,y_train)\n",
    "X_train_maritalStatus_0,X_train_maritalStatus_1 = response_coding('maritalStatus',X_train,y_train)\n",
    "X_train_education_0,X_train_education_1 = response_coding('education',X_train,y_train)\n",
    "X_train_income_0,X_train_income_1 = response_coding('income',X_train,y_train)\n",
    "X_train_Bar_0,X_train_Bar_1 = response_coding('Bar',X_train,y_train)\n",
    "X_train_CoffeeHouse_0,X_train_CoffeeHouse_1 = response_coding('CoffeeHouse',X_train,y_train)\n",
    "X_train_CarryAway_0,X_train_CarryAway_1 = response_coding('CarryAway',X_train,y_train)\n",
    "X_train_RestaurantLessThan20_0,X_train_RestaurantLessThan20_1 = response_coding('RestaurantLessThan20',X_train,y_train)\n",
    "X_train_Restaurant20To50_0,X_train_Restaurant20To50_1 = response_coding('Restaurant20To50',X_train,y_train)\n",
    "X_train_coupon_freq_0,X_train_coupon_freq_1 = response_coding('coupon_freq',X_train,y_train)\n",
    "X_train_occupation_class_0,X_train_occupation_class_1 = response_coding('occupation_class',X_train,y_train)\n",
    "\n",
    "X_test_destination_0,X_test_destination_1 = response_coding('destination',X_test,y_test)\n",
    "X_test_passanger_0,X_test_passanger_1 = response_coding('passanger',X_test,y_test)\n",
    "X_test_weather_0,X_test_weather_1 = response_coding('weather',X_test,y_test)\n",
    "X_test_time_0,X_test_time_1 = response_coding('time',X_test,y_test)\n",
    "X_test_coupon_0,X_test_coupon_1 = response_coding('coupon',X_test,y_test)\n",
    "X_test_expiration_0,X_test_expiration_1 = response_coding('expiration',X_test,y_test)\n",
    "X_test_gender_0,X_test_gender_1 = response_coding('gender',X_test,y_test)\n",
    "X_test_age_0,X_test_age_1 = response_coding('age',X_test,y_test)\n",
    "X_test_maritalStatus_0,X_test_maritalStatus_1 = response_coding('maritalStatus',X_test,y_test)\n",
    "X_test_education_0,X_test_education_1 = response_coding('education',X_test,y_test)\n",
    "X_test_income_0,X_test_income_1 = response_coding('income',X_test,y_test)\n",
    "X_test_Bar_0,X_test_Bar_1 = response_coding('Bar',X_test,y_test)\n",
    "X_test_CoffeeHouse_0,X_test_CoffeeHouse_1 = response_coding('CoffeeHouse',X_test,y_test)\n",
    "X_test_CarryAway_0,X_test_CarryAway_1 = response_coding('CarryAway',X_test,y_test)\n",
    "X_test_RestaurantLessThan20_0,X_test_RestaurantLessThan20_1 = response_coding('RestaurantLessThan20',X_test,y_test)\n",
    "X_test_Restaurant20To50_0,X_test_Restaurant20To50_1 = response_coding('Restaurant20To50',X_test,y_test)\n",
    "X_test_coupon_freq_0,X_test_coupon_freq_1 = response_coding('coupon_freq',X_test,y_test)\n",
    "X_test_occupation_class_0,X_test_occupation_class_1 = response_coding('occupation_class',X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1719be29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization of numerical features\n",
    "def norm(column_name,X):\n",
    "    \"\"\"It returns Normalized feature\"\"\"\n",
    "    normalizer = Normalizer()\n",
    "    normalizer.fit(X[column_name].values.reshape(1,-1))\n",
    "    X_norm = normalizer.transform(X[column_name].values.reshape(1,-1))\n",
    "    return X_norm.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b68119db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_temperature_norm = norm('temperature',X_train)\n",
    "X_train_has_children_norm = norm('has_children',X_train)\n",
    "X_train_toCoupon_GEQ15min_norm = norm('toCoupon_GEQ15min',X_train)\n",
    "X_train_toCoupon_GEQ25min_norm = norm('toCoupon_GEQ25min',X_train)\n",
    "X_train_direction_same_norm = norm('direction_same',X_train)\n",
    "X_train_to_Coupon_norm = norm('to_Coupon',X_train)\n",
    "\n",
    "X_test_temperature_norm = norm('temperature',X_test)\n",
    "X_test_has_children_norm = norm('has_children',X_test)\n",
    "X_test_toCoupon_GEQ15min_norm = norm('toCoupon_GEQ15min',X_test)\n",
    "X_test_toCoupon_GEQ25min_norm = norm('toCoupon_GEQ25min',X_test)\n",
    "X_test_direction_same_norm = norm('direction_same',X_test)\n",
    "X_test_to_Coupon_norm = norm('to_Coupon',X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "008f1ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_response_encoding: (10147, 42) \n",
      "X_test_response_encoding: (2537, 42)\n"
     ]
    }
   ],
   "source": [
    "X_train_response_encoding = np.hstack((X_train_destination_0,X_train_destination_1,X_train_passanger_0,X_train_passanger_1,X_train_weather_0,X_train_weather_1,X_train_time_0,X_train_time_1,X_train_coupon_0,X_train_coupon_1,X_train_expiration_0,X_train_expiration_1,X_train_gender_0,X_train_gender_1,X_train_age_0,X_train_age_1,X_train_maritalStatus_0,X_train_maritalStatus_1,X_train_education_0,X_train_education_1,X_train_income_0,X_train_income_1,X_train_coupon_freq_0,X_train_coupon_freq_1,X_train_occupation_class_0,X_train_occupation_class_1,X_train_Bar_0,X_train_Bar_1,X_train_CoffeeHouse_0,X_train_CoffeeHouse_1,X_train_CarryAway_0,X_train_CarryAway_1,X_train_RestaurantLessThan20_0,X_train_RestaurantLessThan20_1,X_train_Restaurant20To50_0,X_train_Restaurant20To50_1,X_train_temperature_norm,X_train_has_children_norm,X_train_toCoupon_GEQ15min_norm,X_train_toCoupon_GEQ25min_norm,X_train_direction_same_norm,X_train_to_Coupon_norm))\n",
    "X_test_response_encoding = np.hstack((X_test_destination_0,X_test_destination_1,X_test_passanger_0,X_test_passanger_1,X_test_weather_0,X_test_weather_1,X_test_time_0,X_test_time_1,X_test_coupon_0,X_test_coupon_1,X_test_expiration_0,X_test_expiration_1,X_test_gender_0,X_test_gender_1,X_test_age_0,X_test_age_1,X_test_maritalStatus_0,X_test_maritalStatus_1,X_test_education_0,X_test_education_1,X_test_income_0,X_test_income_1,X_test_coupon_freq_0,X_test_coupon_freq_1,X_test_occupation_class_0,X_test_occupation_class_1,X_test_Bar_0,X_test_Bar_1,X_test_CoffeeHouse_0,X_test_CoffeeHouse_1,X_test_CarryAway_0,X_test_CarryAway_1,X_test_RestaurantLessThan20_0,X_test_RestaurantLessThan20_1,X_test_Restaurant20To50_0,X_test_Restaurant20To50_1 ,X_test_temperature_norm,X_test_has_children_norm,X_test_toCoupon_GEQ15min_norm,X_test_toCoupon_GEQ25min_norm,X_test_direction_same_norm,X_test_to_Coupon_norm))\n",
    "print('X_train_response_encoding:',X_train_response_encoding.shape,'\\nX_test_response_encoding:',X_test_response_encoding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee8a574",
   "metadata": {},
   "source": [
    "### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6babc0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding function\n",
    "def ohe(column_name,X):\n",
    "    \"\"\"It returns One hot encoded feature in X data\"\"\"  \n",
    "    X[column_name] = X[column_name].str.replace('~','_')\n",
    "    X[column_name] = X[column_name].str.replace('[^a-zA-Z0-9_ ]',' ')\n",
    "    X[column_name] = X[column_name].str.replace(' +',' ')\n",
    "    X[column_name] = X[column_name].str.strip()\n",
    "    X[column_name] = X[column_name].str.replace(' ','_')\n",
    "    X[column_name] = X[column_name].str.lower()\n",
    "    vectorizer = CountVectorizer(binary=True)\n",
    "    return vectorizer.fit_transform(X[column_name].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "86f71b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_destination_ohe = ohe('destination',X_train)\n",
    "X_train_passanger_ohe = ohe('passanger',X_train)\n",
    "X_train_weather_ohe = ohe('weather',X_train)\n",
    "X_train_time_ohe = ohe('time',X_train)\n",
    "X_train_coupon_ohe = ohe('coupon',X_train)\n",
    "X_train_expiration_ohe = ohe('expiration',X_train)\n",
    "X_train_gender_ohe = ohe('gender',X_train)\n",
    "X_train_age_ohe = ohe('age',X_train)\n",
    "X_train_maritalStatus_ohe = ohe('maritalStatus',X_train)\n",
    "X_train_education_ohe = ohe('education',X_train)\n",
    "X_train_income_ohe = ohe('income',X_train)\n",
    "X_train_Bar_ohe = ohe('Bar',X_train)\n",
    "X_train_CoffeeHouse_ohe = ohe('CoffeeHouse',X_train)\n",
    "X_train_CarryAway_ohe = ohe('CarryAway',X_train)\n",
    "X_train_RestaurantLessThan20_ohe = ohe('RestaurantLessThan20',X_train)\n",
    "X_train_Restaurant20To50_ohe = ohe('Restaurant20To50',X_train)\n",
    "X_train_coupon_freq_ohe = ohe('coupon_freq',X_train)\n",
    "X_train_occupation_class_ohe = ohe('occupation_class',X_train)\n",
    "\n",
    "X_test_destination_ohe = ohe('destination',X_test)\n",
    "X_test_passanger_ohe = ohe('passanger',X_test)\n",
    "X_test_weather_ohe = ohe('weather',X_test)\n",
    "X_test_time_ohe = ohe('time',X_test)\n",
    "X_test_coupon_ohe = ohe('coupon',X_test)\n",
    "X_test_expiration_ohe = ohe('expiration',X_test)\n",
    "X_test_gender_ohe = ohe('gender',X_test)\n",
    "X_test_age_ohe = ohe('age',X_test)\n",
    "X_test_maritalStatus_ohe = ohe('maritalStatus',X_test)\n",
    "X_test_education_ohe = ohe('education',X_test)\n",
    "X_test_income_ohe = ohe('income',X_test)\n",
    "X_test_Bar_ohe = ohe('Bar',X_test)\n",
    "X_test_CoffeeHouse_ohe = ohe('CoffeeHouse',X_test)\n",
    "X_test_CarryAway_ohe = ohe('CarryAway',X_test)\n",
    "X_test_RestaurantLessThan20_ohe = ohe('RestaurantLessThan20',X_test)\n",
    "X_test_Restaurant20To50_ohe = ohe('Restaurant20To50',X_test)\n",
    "X_test_coupon_freq_ohe = ohe('coupon_freq',X_test)\n",
    "X_test_occupation_class_ohe = ohe('occupation_class',X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7201cc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization of numerical features\n",
    "def norm(column_name,X):\n",
    "    \"\"\"It returns Normalized feature\"\"\"\n",
    "    normalizer = Normalizer()\n",
    "    normalizer.fit(X[column_name].values.reshape(1,-1))\n",
    "    X_norm = normalizer.transform(X[column_name].values.reshape(1,-1))\n",
    "    return X_norm.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a1dddf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_temperature_norm = norm('temperature',X_train)\n",
    "X_train_has_children_norm = norm('has_children',X_train)\n",
    "X_train_toCoupon_GEQ15min_norm = norm('toCoupon_GEQ15min',X_train)\n",
    "X_train_toCoupon_GEQ25min_norm = norm('toCoupon_GEQ25min',X_train)\n",
    "X_train_direction_same_norm = norm('direction_same',X_train)\n",
    "X_train_to_Coupon_norm = norm('to_Coupon',X_train)\n",
    "\n",
    "X_test_temperature_norm = norm('temperature',X_test)\n",
    "X_test_has_children_norm = norm('has_children',X_test)\n",
    "X_test_toCoupon_GEQ15min_norm = norm('toCoupon_GEQ15min',X_test)\n",
    "X_test_toCoupon_GEQ25min_norm = norm('toCoupon_GEQ25min',X_test)\n",
    "X_test_direction_same_norm = norm('direction_same',X_test)\n",
    "X_test_to_Coupon_norm = norm('to_Coupon',X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "be856a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_ohe: (10147, 93) \n",
      "X_test_ohe: (2537, 93)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import hstack\n",
    "X_train_ohe = hstack((X_train_destination_ohe, X_train_passanger_ohe, X_train_weather_ohe, X_train_time_ohe, X_train_coupon_ohe, X_train_expiration_ohe, X_train_gender_ohe, X_train_age_ohe, X_train_maritalStatus_ohe, X_train_education_ohe, X_train_income_ohe, X_train_coupon_freq_ohe, X_train_occupation_class_ohe,X_train_Bar_ohe,X_train_CoffeeHouse_ohe,X_train_CarryAway_ohe,X_train_RestaurantLessThan20_ohe,X_train_Restaurant20To50_ohe,X_train_temperature_norm, X_train_has_children_norm,X_train_toCoupon_GEQ15min_norm,X_train_toCoupon_GEQ25min_norm,X_train_direction_same_norm,X_train_to_Coupon_norm)).tocsr()\n",
    "X_test_ohe = hstack((X_test_destination_ohe, X_test_passanger_ohe, X_test_weather_ohe, X_test_time_ohe, X_test_coupon_ohe, X_test_expiration_ohe, X_test_gender_ohe, X_test_age_ohe, X_test_maritalStatus_ohe, X_test_education_ohe, X_test_income_ohe, X_test_coupon_freq_ohe, X_test_occupation_class_ohe,X_test_Bar_ohe,X_test_CoffeeHouse_ohe,X_test_CarryAway_ohe,X_test_RestaurantLessThan20_ohe,X_test_Restaurant20To50_ohe,X_test_temperature_norm, X_test_has_children_norm,X_test_toCoupon_GEQ15min_norm,X_test_toCoupon_GEQ25min_norm,X_test_direction_same_norm,X_test_to_Coupon_norm)).tocsr()\n",
    "print('X_train_ohe:',X_train_ohe.shape,'\\nX_test_ohe:',X_test_ohe.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0748dceb",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3282d238",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f1119a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Decision_Tree_Classifier(x_train,y_train,x_test,y_test):\n",
    "  \"\"\"This function returns best hyperparameter, train and test log_loss & roc_auc_score of Decision Trees Model\"\"\"\n",
    "\n",
    "  clf = DecisionTreeClassifier(class_weight='balanced')\n",
    "  parameters = {'max_depth':[1, 5, 10, 50], 'min_samples_split':[5, 10, 100, 500]}\n",
    "  model = RandomizedSearchCV(clf, parameters, cv=5, scoring='roc_auc') #scoring='roc_auc' or 'neg_log_loss'\n",
    "  model.fit(x_train, y_train)\n",
    "  best_depth = model.best_params_['max_depth']\n",
    "  best_samples_split = model.best_params_['min_samples_split']\n",
    "\n",
    "  clf = DecisionTreeClassifier(class_weight='balanced', max_depth=best_depth, min_samples_split=best_samples_split, random_state=0)\n",
    "  clf.fit(x_train, y_train)\n",
    "\n",
    "  Train_loss = log_loss(y_train,clf.predict_proba(x_train))\n",
    "  Train_AUC = roc_auc_score(y_train,clf.predict_proba(x_train)[:,1])\n",
    "  Test_loss = log_loss(y_test,clf.predict_proba(x_test))\n",
    "  Test_AUC = roc_auc_score(y_test,clf.predict_proba(x_test)[:,1])\n",
    "\n",
    "  return best_depth,best_samples_split,Train_loss,Train_AUC,Test_loss,Test_AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "562b58ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal Encoding\n",
    "best_depth_OrEnc,best_samples_split_OrEnc,Train_loss_OrEnc,Train_AUC_OrEnc,Test_loss_OrEnc,Test_AUC_OrEnc = Decision_Tree_Classifier(X_train_Ordinal_encoding,y_train,X_test_Ordinal_encoding,y_test)\n",
    "# Frequency Encoding\n",
    "best_depth_FreEnc,best_samples_split_FreEnc,Train_loss_FreEnc,Train_AUC_FreEnc,Test_loss_FreEnc,Test_AUC_FreEnc = Decision_Tree_Classifier(X_train_frequency_encoding,y_train,X_test_frequency_encoding,y_test)\n",
    "# Target Encoding\n",
    "best_depth_TarEnc,best_samples_split_TarEnc,Train_loss_TarEnc,Train_AUC_TarEnc,Test_loss_TarEnc,Test_AUC_TarEnc = Decision_Tree_Classifier(X_train_target_encoding,y_train,X_test_target_encoding,y_test)\n",
    "# Response Encoding\n",
    "best_depth_ResEnc,best_samples_split_ResEnc,Train_loss_ResEnc,Train_AUC_ResEnc,Test_loss_ResEnc,Test_AUC_ResEnc = Decision_Tree_Classifier(X_train_response_encoding,y_train,X_test_response_encoding,y_test)\n",
    "# One Hot Encoding\n",
    "best_depth_ohe,best_samples_split_ohe,Train_loss_ohe,Train_AUC_ohe,Test_loss_ohe,Test_AUC_ohe = Decision_Tree_Classifier(X_train_ohe,y_train,X_test_ohe,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b6b3ab2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Encoding</th>\n",
       "      <th>Hyperparameter1</th>\n",
       "      <th>Hyperparameter2</th>\n",
       "      <th>Train_log_loss</th>\n",
       "      <th>Train_roc_auc_score</th>\n",
       "      <th>Test_log_loss</th>\n",
       "      <th>Test_roc_auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Ordinal Encoding</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Frequency Encoding</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Target Encoding</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Response Encoding</td>\n",
       "      <td>50</td>\n",
       "      <td>500</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>One Hot Encoding</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model            Encoding  Hyperparameter1  Hyperparameter2  \\\n",
       "0  Decision Tree    Ordinal Encoding               10              100   \n",
       "1  Decision Tree  Frequency Encoding               50              100   \n",
       "2  Decision Tree     Target Encoding               10              500   \n",
       "3  Decision Tree   Response Encoding               50              500   \n",
       "4  Decision Tree    One Hot Encoding               50              100   \n",
       "\n",
       "   Train_log_loss  Train_roc_auc_score  Test_log_loss  Test_roc_auc_score  \n",
       "0           0.519                0.817          0.596               0.762  \n",
       "1           0.513                0.821          0.664               0.753  \n",
       "2           0.566                0.774          0.583               0.763  \n",
       "3           0.566                0.774          0.584               0.758  \n",
       "4           0.504                0.826          0.745               0.766  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_table = PrettyTable([\"Model\",\"Encoding\", \"Hyperparameter1\", \"Hyperparameter2\", \"Train_log_loss\", \"Train_roc_auc_score\", \"Test_log_loss\", \"Test_roc_auc_score\"]) #heading\n",
    "\n",
    "summary_table.add_row([\"Decision Tree\",\"Ordinal Encoding\",best_depth_OrEnc,best_samples_split_OrEnc,round(Train_loss_OrEnc,3),round(Train_AUC_OrEnc,3),round(Test_loss_OrEnc,3),round(Test_AUC_OrEnc,3)])\n",
    "summary_table.add_row([\"Decision Tree\",\"Frequency Encoding\",best_depth_FreEnc,best_samples_split_FreEnc,round(Train_loss_FreEnc,3),round(Train_AUC_FreEnc,3),round(Test_loss_FreEnc,3),round(Test_AUC_FreEnc,3)])\n",
    "summary_table.add_row([\"Decision Tree\",\"Target Encoding\",best_depth_TarEnc,best_samples_split_TarEnc,round(Train_loss_TarEnc,3),round(Train_AUC_TarEnc,3),round(Test_loss_TarEnc,3),round(Test_AUC_TarEnc,3)])\n",
    "summary_table.add_row([\"Decision Tree\",\"Response Encoding\",best_depth_ResEnc,best_samples_split_ResEnc,round(Train_loss_ResEnc,3),round(Train_AUC_ResEnc,3),round(Test_loss_ResEnc,3),round(Test_AUC_ResEnc,3)])\n",
    "summary_table.add_row([\"Decision Tree\",\"One Hot Encoding\",best_depth_ohe,best_samples_split_ohe,round(Train_loss_ohe,3),round(Train_AUC_ohe,3),round(Test_loss_ohe,3),round(Test_AUC_ohe,3)])\n",
    "\n",
    "table = pd.read_html(summary_table.get_html_string())\n",
    "Decision_Tree_Result = table[0]\n",
    "Decision_Tree_Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c886b471",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0b16a251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Random_Forest_Classifier(x_train,y_train,x_test,y_test):\n",
    "  \"\"\"This function returns best hyperparameter, train and test log_loss & roc_auc_score of Random_Forest Model\"\"\"\n",
    "\n",
    "  clf = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None,max_features='log2',min_samples_leaf=3,random_state=42, n_jobs=-1)\n",
    "  parameters = {'max_depth':[20, 50, 100], 'n_estimators':[1000,2000]}\n",
    "  model = RandomizedSearchCV(clf, parameters, cv=5, scoring='roc_auc') #scoring='roc_auc' or 'neg_log_loss'\n",
    "  model.fit(x_train, y_train)\n",
    "  best_depth = model.best_params_['max_depth']\n",
    "  best_n_estimators = model.best_params_['n_estimators']\n",
    "\n",
    "  clf = RandomForestClassifier(n_estimators=best_n_estimators,criterion='gini',max_depth=best_depth,max_features='log2',min_samples_leaf=3, random_state=42, n_jobs=-1)\n",
    "  clf.fit(x_train, y_train)\n",
    "\n",
    "  Train_loss = log_loss(y_train,clf.predict_proba(x_train))\n",
    "  Train_AUC = roc_auc_score(y_train,clf.predict_proba(x_train)[:,1])\n",
    "  Test_loss = log_loss(y_test,clf.predict_proba(x_test))\n",
    "  Test_AUC = roc_auc_score(y_test,clf.predict_proba(x_test)[:,1])\n",
    "\n",
    "  return best_depth,best_n_estimators,Train_loss,Train_AUC,Test_loss,Test_AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5099a86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal Encoding\n",
    "best_depth_OrEnc,best_n_estimators_OrEnc,Train_loss_OrEnc,Train_AUC_OrEnc,Test_loss_OrEnc,Test_AUC_OrEnc = Random_Forest_Classifier(X_train_Ordinal_encoding,y_train,X_test_Ordinal_encoding,y_test)\n",
    "# Frequency Encoding\n",
    "best_depth_FreEnc,best_n_estimators_FreEnc,Train_loss_FreEnc,Train_AUC_FreEnc,Test_loss_FreEnc,Test_AUC_FreEnc = Random_Forest_Classifier(X_train_frequency_encoding,y_train,X_test_frequency_encoding,y_test)\n",
    "# Target Encoding\n",
    "best_depth_TarEnc,best_n_estimators_TarEnc,Train_loss_TarEnc,Train_AUC_TarEnc,Test_loss_TarEnc,Test_AUC_TarEnc = Random_Forest_Classifier(X_train_target_encoding,y_train,X_test_target_encoding,y_test)\n",
    "# Response Encoding\n",
    "best_depth_ResEnc,best_n_estimators_ResEnc,Train_loss_ResEnc,Train_AUC_ResEnc,Test_loss_ResEnc,Test_AUC_ResEnc = Random_Forest_Classifier(X_train_response_encoding,y_train,X_test_response_encoding,y_test)\n",
    "# One Hot Encoding\n",
    "best_depth_ohe,best_n_estimators_ohe,Train_loss_ohe,Train_AUC_ohe,Test_loss_ohe,Test_AUC_ohe = Random_Forest_Classifier(X_train_ohe,y_train,X_test_ohe,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0f7019",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table = PrettyTable([\"Model\",\"Encoding\", \"Hyperparameter1\", \"Hyperparameter2\", \"Train_log_loss\", \"Train_roc_auc_score\", \"Test_log_loss\", \"Test_roc_auc_score\"]) #heading\n",
    "\n",
    "summary_table.add_row([\"Random Forest\",\"Ordinal Encoding\",best_depth_OrEnc,best_n_estimators_OrEnc,round(Train_loss_OrEnc,3),round(Train_AUC_OrEnc,3),round(Test_loss_OrEnc,3),round(Test_AUC_OrEnc,3)])\n",
    "summary_table.add_row([\"Random Forest\",\"Frequency Encoding\",best_depth_FreEnc,best_n_estimators_FreEnc,round(Train_loss_FreEnc,3),round(Train_AUC_FreEnc,3),round(Test_loss_FreEnc,3),round(Test_AUC_FreEnc,3)])\n",
    "summary_table.add_row([\"Random Forest\",\"Target Encoding\",best_depth_TarEnc,best_n_estimators_TarEnc,round(Train_loss_TarEnc,3),round(Train_AUC_TarEnc,3),round(Test_loss_TarEnc,3),round(Test_AUC_TarEnc,3)])\n",
    "summary_table.add_row([\"Random Forest\",\"Response Encoding\",best_depth_ResEnc,best_n_estimators_ResEnc,round(Train_loss_ResEnc,3),round(Train_AUC_ResEnc,3),round(Test_loss_ResEnc,3),round(Test_AUC_ResEnc,3)])\n",
    "summary_table.add_row([\"Random Forest\",\"One Hot Encoding\",best_depth_ohe,best_n_estimators_ohe,round(Train_loss_ohe,3),round(Train_AUC_ohe,3),round(Test_loss_ohe,3),round(Test_AUC_ohe,3)])\n",
    "\n",
    "table = pd.read_html(summary_table.get_html_string())\n",
    "Random_Forest_Classifier_Result = table[0]\n",
    "Random_Forest_Classifier_Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efca7629",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
